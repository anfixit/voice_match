import os
import json
import librosa
import numpy as np
import tensorflow as tf
import torch
import webrtcvad
import soundfile as sf
import noisereduce as nr
import scipy.signal
import scipy.stats
import logging
from app.log import setup_logger
from functools import lru_cache
from typing import Dict, List, Tuple, Optional, Union
from audiomentations import Compose, Normalize, BandPassFilter

from models.yamnet import get_yamnet
from models.xvector import get_xvector
from models.ecapa import get_ecapa
from models.resemblyzer import get_resemblyzer

# –ò–º–ø–æ—Ä—Ç—ã –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
from models.antispoofing import get_antispoofing_detector
from models.formant_tracker import get_formant_tracker
from models.voice_features import get_voice_feature_extractor

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
log = setup_logger("voice_match")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SAMPLE_RATE = 16000
SEGMENT_DURATION = 30.0
SEGMENT_COUNT = 5
CONFIDENCE_LEVEL = 0.95  # –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª—å–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫
# –ê–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ —Ñ–æ—Ä–º–∞–Ω—Ç—ã –≤ Hz –¥–ª—è –≤–∑—Ä–æ—Å–ª–æ–≥–æ –º—É–∂—á–∏–Ω—ã
FORMANT_LIMITS = {
    "F1": (100, 1000),  # –ì–ª–∞—Å–Ω—ã–µ –∑–≤—É–∫–∏
    "F2": (800, 2500),  # –ì–ª–∞—Å–Ω—ã–µ –∑–≤—É–∫–∏
    "F3": (1500, 3500),  # –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ç—Ä–∞–∫—Ç–∞
    "F4": (3000, 5000)  # –ê–Ω–∞—Ç–æ–º–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞, —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞
}
# –î–∏–∞–ø–∞–∑–æ–Ω—ã –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –¥–∂–∏—Ç—Ç–µ—Ä–∞/—à–∏–º–º–µ—Ä–∞ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞
JITTER_NORMAL_RANGE = (0.0, 1.04)  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
SHIMMER_NORMAL_RANGE = (0.0, 3.81)  # –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
# –¢–∏–ø–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–æ–ª–æ—Å–æ–≤—ã—Ö –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
VOICE_MODIFIERS = {
    "pitch_shift": (-12, 12),  # –ü–æ–ª—É—Ç–æ–Ω—ã
    "formant_shift": (0.5, 2.0),  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
    "robot": {"harmonic_intensity": (0.7, 1.0)}
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
augment = Compose([
    Normalize(p=1.0),
    BandPassFilter(min_center_freq=100, max_center_freq=7500, p=1.0),
])

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –í–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DEFAULT_WEIGHTS = {
    "ecapa": 1.5,  # –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ —Ä–µ—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    "xvec": 1.5,  # –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    "res": 1.2,  # –û–±—â–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –≥–æ–ª–æ—Å–∞
    "formant": 1.0,  # –ê–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
    "formant_dynamics": 1.5,  # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º–∞–Ω—Ç
    "fricative": 1.2,  # –§—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã–µ —Å–æ–≥–ª–∞—Å–Ω—ã–µ
    "nasal": 1.3,  # –ù–æ—Å–æ–≤—ã–µ —Ä–µ–∑–æ–Ω–∞–Ω—Å—ã
    "vocal_tract": 1.8,  # –î–ª–∏–Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞
    "jitter_shimmer": 1.1,  # –ú–∏–∫—Ä–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞
    "yamnet": 0.8  # –ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
}

try:
    with open("../weights.json", "r") as f:
        weights = json.load(f)
        log.info("–í–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ weights.json")
except Exception:
    weights = DEFAULT_WEIGHTS
    log.warning("weights.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –î–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ—á–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
vad = webrtcvad.Vad(3)  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ú–æ–¥–µ–ª–∏ (–ª–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@lru_cache(maxsize=1)
def lazy_ecapa():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç ECAPA-TDNN –º–æ–¥–µ–ª—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    return get_ecapa()


@lru_cache(maxsize=1)
def lazy_xvector():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç x-vector –º–æ–¥–µ–ª—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    return get_xvector()


@lru_cache(maxsize=1)
def lazy_yamnet():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç YAMNet –º–æ–¥–µ–ª—å –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    return get_yamnet()


@lru_cache(maxsize=1)
def lazy_res():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç Resemblyzer –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    return get_resemblyzer()


@lru_cache(maxsize=1)
def lazy_antispoofing():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–µ—Ç–µ–∫—Ç–æ—Ä –ø–æ–¥–¥–µ–ª–æ–∫ –≥–æ–ª–æ—Å–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    from models.antispoofing import get_antispoofing_detector
    return get_antispoofing_detector()


@lru_cache(maxsize=1)
def lazy_formant_tracker():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–µ–∫–µ—Ä —Ñ–æ—Ä–º–∞–Ω—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    from models.formant_tracker import get_formant_tracker
    return get_formant_tracker()


@lru_cache(maxsize=1)
def lazy_voice_features():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    from models.voice_features import get_voice_feature_extractor
    return get_voice_feature_extractor()


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def preprocess(y: np.ndarray) -> np.ndarray:
    """
    –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞:
    1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–º–ø–ª–∏—Ç—É–¥—ã
    2. –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
    3. –ü–æ–ª–æ—Å–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ numpy array

    Returns:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–º–ø–ª–∏—Ç—É–¥—ã
    y = librosa.util.normalize(y)

    # –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ—á–µ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
    y = nr.reduce_noise(
        y=y,
        sr=SAMPLE_RATE,
        stationary=False,  # –ù–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–π —à—É–º (–±–æ–ª–µ–µ —Ç–æ—á–Ω–æ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π)
        prop_decrease=0.75  # –°–æ—Ö—Ä–∞–Ω—è–µ–º 25% —à—É–º–∞ –¥–ª—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏
    )

    # –ü–æ–ª–æ—Å–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞
    y = augment(samples=y, sample_rate=SAMPLE_RATE)

    return y


def get_segments(y: np.ndarray, sr: int, duration: float = SEGMENT_DURATION,
                 count: int = SEGMENT_COUNT) -> List[np.ndarray]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Ä–µ—á–∏ –∏–∑ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º.
    –í—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç—ã —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–π —Ä–µ—á—å—é.

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
        duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        count: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å —Ä–µ—á—å—é
    """
    window_size = int(sr * duration)
    hop = int(sr * duration / 2)  # 50% –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
    segments = []

    # –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω–µ—Ä–≥–∏—é —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–µ–π–º–∞
    energy = librosa.feature.rms(y=y)[0]
    energy_norm = energy / np.max(energy) if np.max(energy) > 0 else energy

    # –ù–∞—Ö–æ–¥–∏–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å –≤—ã—Å–æ–∫–æ–π —ç–Ω–µ—Ä–≥–∏–µ–π
    energy_segments = []
    for start in range(0, len(y) - window_size, hop):
        end = start + window_size
        segment = y[start:end]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ—á–∏ —Å –ø–æ–º–æ—â—å—é VAD
        if is_voiced(segment, sr):
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —ç–Ω–µ—Ä–≥–∏—é —Å–µ–≥–º–µ–Ω—Ç–∞
            start_frame = start // hop
            end_frame = min(start_frame + (window_size // hop), len(energy_norm))
            mean_energy = np.mean(energy_norm[start_frame:end_frame])

            energy_segments.append((segment, mean_energy, start))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ —ç–Ω–µ—Ä–≥–∏–∏ (–æ—Ç –≤—ã—Å–æ–∫–æ–π –∫ –Ω–∏–∑–∫–æ–π)
    energy_segments.sort(key=lambda x: x[1], reverse=True)

    # –ë–µ—Ä–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —ç–Ω–µ—Ä–≥–∏–µ–π, –Ω–æ —Å—Ç–∞—Ä–∞–µ–º—Å—è –≤—ã–±—Ä–∞—Ç—å
    # –∏–∑ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π –∑–∞–ø–∏—Å–∏ (–Ω–µ –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ)
    selected_segments = []
    selected_starts = set()

    for segment, _, start in energy_segments:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ª–∏ —Å —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏
        is_overlapping = False
        for sel_start in selected_starts:
            if abs(start - sel_start) < window_size // 2:
                is_overlapping = True
                break

        if not is_overlapping:
            selected_segments.append(segment)
            selected_starts.add(start)

            if len(selected_segments) >= count:
                break

    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –º–µ–Ω—å—à–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤, —á–µ–º –Ω—É–∂–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —á—Ç–æ –µ—Å—Ç—å
    if len(selected_segments) < count and energy_segments:
        remaining = count - len(selected_segments)
        for segment, _, _ in energy_segments:
            if segment not in selected_segments:
                selected_segments.append(segment)
                if len(selected_segments) >= count:
                    break

    return selected_segments


def is_voiced(segment: np.ndarray, sr: int) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ä–µ—á–∏ –≤ —Å–µ–≥–º–µ–Ω—Ç–µ —Å –ø–æ–º–æ—â—å—é WebRTC VAD.

    Args:
        segment: –°–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–∞
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        True –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ä–µ—á—å, –∏–Ω–∞—á–µ False
    """
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 16-–±–∏—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è VAD
    int16_audio = (segment * 32767).astype(np.int16)

    # –†–∞–∑–º–µ—Ä —Ñ—Ä–µ–π–º–∞ –¥–ª—è VAD (30 –º—Å —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
    frame_size = int(sr * 30 / 1000)
    voice_frames = 0
    total_frames = 0

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ—Ä–µ–π–º—ã
    for i in range(0, len(int16_audio) - frame_size, frame_size):
        frame = int16_audio[i:i + frame_size].tobytes()
        if vad.is_speech(frame, sr):
            voice_frames += 1
        total_frames += 1

    # –ï—Å–ª–∏ –±–æ–ª–µ–µ 15% —Ñ—Ä–µ–π–º–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–µ—á—å, —Å—á–∏—Ç–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç —Ä–µ—á–µ–≤—ã–º
    return voice_frames > 0.15 * total_frames if total_frames > 0 else False


def detect_voice_modification(y: np.ndarray, sr: int) -> Tuple[bool, Optional[str]]:
    """
    –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤.

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        (is_modified, modifier_type): –§–ª–∞–≥ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ —Ç–∏–ø –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    """
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    pitched_segments = 0
    total_segments = 0
    frame_length = 2048
    hop_length = 512

    # –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–æ–Ω–∞
    pitches, magnitudes = librosa.core.piptrack(
        y=y, sr=sr,
        n_fft=frame_length,
        hop_length=hop_length,
        fmin=50,
        fmax=400
    )

    # –ò—â–µ–º –Ω–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–∫–∞—á–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–æ–Ω–∞
    pitch_changes = []
    prev_pitch = None

    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–µ–π–º–∞ –Ω–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –º–∞–≥–Ω–∏—Ç—É–¥—É
    for t in range(pitches.shape[1]):
        index = magnitudes[:, t].argmax()
        pitch = pitches[index, t]

        # –ï—Å–ª–∏ —Ç–æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω (–Ω–µ –Ω–æ–ª—å)
        if pitch > 0:
            if prev_pitch is not None and prev_pitch > 0:
                # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –ø–æ–ª—É—Ç–æ–Ω–∞—Ö
                semitones = 12 * np.log2(pitch / prev_pitch)
                pitch_changes.append(abs(semitones))
            prev_pitch = pitch
            pitched_segments += 1
        total_segments += 1

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≥–æ–ª–æ—Å–∞
    if pitched_segments > 0:
        # 1. –ù–µ–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–∫–∞—á–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–æ–Ω–∞
        if pitch_changes and np.percentile(pitch_changes, 95) > 5.0:
            return True, "pitch_shift"

        # 2. –ü—Ä–∏–∑–Ω–∞–∫–∏ "—Ä–æ–±–æ—Ç–∞": —Å–ª–∏—à–∫–æ–º —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ç–æ–Ω
        if np.std(pitch_changes) < 0.1 and pitched_segments > 0.5 * total_segments:
            return True, "robot_voice"

        # 3. –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–¥—É–ª—è—Ü–∏—è —Ñ–æ—Ä–º–∞–Ω—Ç
        formants = extract_formants_advanced(y, sr)
        if formants is not None:
            f1_std = np.std(formants["F1"]) if formants["F1"].size > 0 else 0
            f2_std = np.std(formants["F2"]) if formants["F2"].size > 0 else 0

            # –°–ª–∏—à–∫–æ–º —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞–Ω—Ç—ã - –ø—Ä–∏–∑–Ω–∞–∫ Voice Changer'–∞
            if (f1_std < 10 or f2_std < 20) and pitched_segments > 0.5 * total_segments:
                return True, "formant_modification"

    return False, None


def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏.

    Args:
        v1: –ü–µ—Ä–≤—ã–π –≤–µ–∫—Ç–æ—Ä
        v2: –í—Ç–æ—Ä–æ–π –≤–µ–∫—Ç–æ—Ä

    Returns:
        –ó–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –æ—Ç -1 –¥–æ 1
    """
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤
    v1_norm = np.linalg.norm(v1)
    v2_norm = np.linalg.norm(v2)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω—É–ª–µ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
    if v1_norm == 0 or v2_norm == 0:
        return 0.0

    v1 = v1 / v1_norm
    v2 = v2 / v2_norm

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
    return np.dot(v1, v2)


def extract_formants_advanced(y: np.ndarray, sr: int, order: int = 16) -> Dict[str, np.ndarray]:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞–Ω—Ç —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –¥–∏–Ω–∞–º–∏–∫–∏.

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
        order: –ü–æ—Ä—è–¥–æ–∫ LPC-–∞–Ω–∞–ª–∏–∑–∞

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ñ–æ—Ä–º–∞–Ω—Ç–∞–º–∏ F1-F4 –∏ –∏—Ö –¥–∏–Ω–∞–º–∏–∫–æ–π
    """
    try:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–∫–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        frame_length = int(0.025 * sr)  # 25 –º—Å –æ–∫–Ω–æ
        hop_length = int(0.010 * sr)  # 10 –º—Å —à–∞–≥

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        formants_result = {
            "F1": np.array([]),
            "F2": np.array([]),
            "F3": np.array([]),
            "F4": np.array([]),
            "F1_bandwidth": np.array([]),
            "F2_bandwidth": np.array([]),
            "F3_bandwidth": np.array([]),
            "F4_bandwidth": np.array([]),
        }

        # –ü—Ä–æ—Ö–æ–¥ –ø–æ —Ñ—Ä–µ–π–º–∞–º
        for i in range(0, len(y) - frame_length, hop_length):
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—Ä–µ–π–º
            frame = y[i:i + frame_length]

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–∫–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –∫—Ä–∞–µ–≤—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
            frame = frame * np.hamming(len(frame))

            # –í—ã–ø–æ–ª–Ω—è–µ–º LPC-–∞–Ω–∞–ª–∏–∑
            A = librosa.lpc(frame, order=order)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç–Ω—É—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É
            w, h = scipy.signal.freqz(1, A, worN=2000)
            freqs = w * sr / (2 * np.pi)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫ –∞–º–ø–ª–∏—Ç—É–¥–∞–º
            magnitude = np.abs(h)

            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫–∏ (—Ñ–æ—Ä–º–∞–Ω—Ç—ã)
            peaks, properties = scipy.signal.find_peaks(
                magnitude,
                height=0.1,
                distance=5,
                prominence=0.1
            )

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ
            sorted_peaks = sorted(peaks, key=lambda x: freqs[x])

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º —Ñ–æ—Ä–º–∞–Ω—Ç
            valid_formants = []
            for peak in sorted_peaks:
                freq = freqs[peak]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–ø–∞–¥–∞–µ—Ç –ª–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω –∫–∞–∫–æ–π-–ª–∏–±–æ —Ñ–æ—Ä–º–∞–Ω—Ç—ã
                for i, (formant, (fmin, fmax)) in enumerate(FORMANT_LIMITS.items(), 1):
                    if fmin <= freq <= fmax:
                        valid_formants.append((i, freq, peak))
                        break

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —Ñ–æ—Ä–º–∞–Ω—Ç—ã
            grouped_formants = {}
            for num, freq, peak in valid_formants:
                if num not in grouped_formants:
                    grouped_formants[num] = []
                grouped_formants[num].append((freq, peak))

            # –î–ª—è –∫–∞–∂–¥–æ–π —Ñ–æ—Ä–º–∞–Ω—Ç—ã –≤—ã–±–∏—Ä–∞–µ–º –ø–æ –æ–¥–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∞–º–ø–ª–∏—Ç—É–¥–æ–π
            for i in range(1, 5):  # F1-F4
                formant_key = f"F{i}"
                bandwidth_key = f"F{i}_bandwidth"

                if i in grouped_formants and grouped_formants[i]:
                    # –í—ã–±–∏—Ä–∞–µ–º –ø–∏–∫ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –∞–º–ø–ª–∏—Ç—É–¥–æ–π
                    best_peak = max(grouped_formants[i], key=lambda x: magnitude[x[1]])
                    formants_result[formant_key] = np.append(formants_result[formant_key], best_peak[0])

                    # –û—Ü–µ–Ω–∫–∞ —à–∏—Ä–∏–Ω—ã –ø–æ–ª–æ—Å—ã (bandwidth)
                    peak_idx = best_peak[1]
                    peak_value = magnitude[peak_idx]
                    half_power = peak_value / np.sqrt(2)

                    # –ò—â–µ–º —Ç–æ—á–∫–∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å —É—Ä–æ–≤–Ω–µ–º –ø–æ–ª–æ–≤–∏–Ω–Ω–æ–π –º–æ—â–Ω–æ—Å—Ç–∏
                    left_idx = peak_idx
                    while left_idx > 0 and magnitude[left_idx] > half_power:
                        left_idx -= 1

                    right_idx = peak_idx
                    while right_idx < len(magnitude) - 1 and magnitude[right_idx] > half_power:
                        right_idx += 1

                    # –í—ã—á–∏—Å–ª—è–µ–º —à–∏—Ä–∏–Ω—É –ø–æ–ª–æ—Å—ã –ø—Ä–æ–ø—É—Å–∫–∞–Ω–∏—è
                    bandwidth = freqs[right_idx] - freqs[left_idx]
                    formants_result[bandwidth_key] = np.append(formants_result[bandwidth_key], bandwidth)

        return formants_result
    except Exception as e:
        log.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ñ–æ—Ä–º–∞–Ω—Ç: {e}")
        return None


def extract_formant_dynamics(formants: Dict[str, np.ndarray]) -> np.ndarray:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–∏–Ω–∞–º–∏–∫–∏ —Ñ–æ—Ä–º–∞–Ω—Ç, –≤–∞–∂–Ω—ã–µ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.

    Args:
        formants: –°–ª–æ–≤–∞—Ä—å —Å —Ñ–æ—Ä–º–∞–Ω—Ç–∞–º–∏ –∏–∑ extract_formants_advanced

    Returns:
        –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–∏–Ω–∞–º–∏–∫–∏ —Ñ–æ—Ä–º–∞–Ω—Ç
    """
    if formants is None:
        return np.zeros(12)

    features = []

    # –î–ª—è –∫–∞–∂–¥–æ–π —Ñ–æ—Ä–º–∞–Ω—Ç—ã –∏–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    for key in ["F1", "F2", "F3", "F4"]:
        values = formants[key]
        if len(values) > 2:  # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
            # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            features.append(np.mean(values))

            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ (–≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å)
            features.append(np.std(values))

            # –î–∏–∞–ø–∞–∑–æ–Ω (—Ä–∞–∑–º–∞—Ö)
            features.append(np.max(values) - np.min(values))
        else:
            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –¥–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–∏
            features.extend([0, 0, 0])

    return np.array(features)


def extract_vocal_tract_length(formants: Dict[str, np.ndarray]) -> float:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–ª–∏–Ω—É –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–æ—Ä–º–∞–Ω—Ç F1-F4.
    –î–ª–∏–Ω–∞ —Ç—Ä–∞–∫—Ç–∞ - –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞, –Ω–µ –º–µ–Ω—è—é—â–∞—è—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º.

    Args:
        formants: –°–ª–æ–≤–∞—Ä—å —Å —Ñ–æ—Ä–º–∞–Ω—Ç–∞–º–∏

    Returns:
        –û—Ü–µ–Ω–∫–∞ –¥–ª–∏–Ω—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞ –≤ —Å–º
    """
    if formants is None:
        return 0.0

    # –î–ª—è –æ—Ü–µ–Ω–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞–Ω—Ç—ã F3 –∏ F4 (–Ω–∞–∏–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ)
    f3_values = formants["F3"]
    f4_values = formants["F4"]

    if len(f3_values) > 0 and len(f4_values) > 0:
        # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–æ—Ä–º–∞–Ω—Ç
        f3_mean = np.mean(f3_values)
        f4_mean = np.mean(f4_values)

        # –û—Ü–µ–Ω–∫–∞ –¥–ª–∏–Ω—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞
        # VTL (—Å–º) = c / (2 * F3), –≥–¥–µ c - —Å–∫–æ—Ä–æ—Å—Ç—å –∑–≤—É–∫–∞ –≤ –≤–æ–∑–¥—É—Ö–µ (34400 —Å–º/—Å)
        vtl_from_f3 = 34400 / (2 * f3_mean)
        vtl_from_f4 = 34400 / (2 * f4_mean)

        # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ (—Å—Ä–µ–¥–Ω–µ–µ)
        return (vtl_from_f3 + vtl_from_f4) / 2

    return 0.0


def extract_fricative_features(y: np.ndarray, sr: int) -> np.ndarray:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ñ—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã—Ö —Å–æ–≥–ª–∞—Å–Ω—ã—Ö (—à, —Å, —Ñ, –≤, etc).
    –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —ç—Ç–∏—Ö –∑–≤—É–∫–æ–≤ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –∞–Ω–∞—Ç–æ–º–∏–∏ —Ä–µ—á–µ–≤–æ–≥–æ –∞–ø–ø–∞—Ä–∞—Ç–∞.

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã—Ö –∑–≤—É–∫–æ–≤
    """
    try:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        frame_length = int(0.025 * sr)
        hop_length = int(0.010 * sr)

        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        spec_centroid = librosa.feature.spectral_centroid(
            y=y, sr=sr, n_fft=frame_length, hop_length=hop_length).flatten()

        spec_flatness = librosa.feature.spectral_flatness(
            y=y, n_fft=frame_length, hop_length=hop_length).flatten()

        # –≠–Ω–µ—Ä–≥–∏—è –≤ –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ –¥–ª—è —Ñ—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã—Ö)
        stft = np.abs(librosa.stft(y, n_fft=frame_length, hop_length=hop_length))

        # –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ –ø–æ–ª–æ—Å—ã –¥–ª—è —Ñ—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã—Ö
        # 1. 2000-4000 Hz (s, z)
        # 2. 4000-8000 Hz (sh, zh)
        freq_bins = librosa.fft_frequencies(sr=sr, n_fft=frame_length)
        mask_s = (freq_bins >= 2000) & (freq_bins <= 4000)
        mask_sh = (freq_bins >= 4000) & (freq_bins <= 8000)

        energy_s = np.mean(stft[mask_s, :], axis=0)
        energy_sh = np.mean(stft[mask_sh, :], axis=0)

        # –û—Ç–Ω–æ—à–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–π - —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π
        ratio = np.zeros_like(energy_s)
        mask = energy_s > 0
        ratio[mask] = energy_sh[mask] / energy_s[mask]

        # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã—Ö
        features = np.array([
            np.mean(spec_centroid),
            np.std(spec_centroid),
            np.mean(spec_flatness),
            np.std(spec_flatness),
            np.mean(energy_s),
            np.mean(energy_sh),
            np.mean(ratio),
            np.std(ratio)
        ])

        return features
    except Exception as e:
        log.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã—Ö: {e}")
        return np.zeros(8)


def extract_nasal_features(y: np.ndarray, sr: int) -> np.ndarray:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–æ—Å–æ–≤—ã—Ö –∑–≤—É–∫–æ–≤ (–º, –Ω).
    –ù–æ—Å–æ–≤—ã–µ —Ä–µ–∑–æ–Ω–∞–Ω—Å—ã - —É–Ω–∏–∫–∞–ª—å–Ω–∞—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –≥–æ–ª–æ—Å–∞.

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–æ—Å–æ–≤—ã—Ö –∑–≤—É–∫–æ–≤
    """
    try:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        frame_length = int(0.025 * sr)
        hop_length = int(0.010 * sr)

        # STFT –¥–ª—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        S = np.abs(librosa.stft(y, n_fft=frame_length, hop_length=hop_length))

        # –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ –ø–æ–ª–æ—Å—ã –¥–ª—è –Ω–æ—Å–æ–≤—ã—Ö —Ä–µ–∑–æ–Ω–∞–Ω—Å–æ–≤
        # –û—Å–Ω–æ–≤–Ω–æ–π –Ω–æ—Å–æ–≤–æ–π —Ä–µ–∑–æ–Ω–∞–Ω—Å: 250-450 Hz
        # –í—Ç–æ—Ä–æ–π –Ω–æ—Å–æ–≤–æ–π —Ä–µ–∑–æ–Ω–∞–Ω—Å: 1000-1200 Hz
        freq_bins = librosa.fft_frequencies(sr=sr, n_fft=frame_length)
        mask_nasal1 = (freq_bins >= 250) & (freq_bins <= 450)
        mask_nasal2 = (freq_bins >= 1000) & (freq_bins <= 1200)

        # –°—Ä–µ–¥–Ω—è—è —ç–Ω–µ—Ä–≥–∏—è –≤ –ø–æ–ª–æ—Å–∞—Ö
        energy_nasal1 = np.mean(S[mask_nasal1, :], axis=0)
        energy_nasal2 = np.mean(S[mask_nasal2, :], axis=0)

        # –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–æ –≤—Å–µ–º—É —Å–ø–µ–∫—Ç—Ä—É
        energy_total = np.mean(S, axis=0)
        ratio1 = np.zeros_like(energy_nasal1)
        ratio2 = np.zeros_like(energy_nasal2)

        mask = energy_total > 0
        ratio1[mask] = energy_nasal1[mask] / energy_total[mask]
        ratio2[mask] = energy_nasal2[mask] / energy_total[mask]

        # –°–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = np.array([
            np.mean(energy_nasal1),
            np.std(energy_nasal1),
            np.mean(energy_nasal2),
            np.std(energy_nasal2),
            np.mean(ratio1),
            np.std(ratio1),
            np.mean(ratio2),
            np.std(ratio2)
        ])

        return features
    except Exception as e:
        log.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–æ—Å–æ–≤—ã—Ö: {e}")
        return np.zeros(8)


def extract_jitter_shimmer(y: np.ndarray, sr: int) -> np.ndarray:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –º–∏–∫—Ä–æ–≤–∞—Ä–∏–∞—Ü–∏–π –≥–æ–ª–æ—Å–∞: –¥–∂–∏—Ç—Ç–µ—Ä –∏ —à–∏–º–º–µ—Ä.
    –≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—á–µ–Ω—å —Ç—Ä—É–¥–Ω–æ –ø–æ–¥–¥–µ–ª–∞—Ç—å –¥–∞–∂–µ –≥–æ–ª–æ—Å–æ–≤—ã–º –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º.

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥—Ä–æ–∂–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞
    """
    try:
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        frame_length = int(0.025 * sr)
        hop_length = int(0.01 * sr)

        # –ù–∞—Ö–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–æ–Ω –≤–æ –≤—Å–µ—Ö —Ñ—Ä–µ–π–º–∞—Ö
        pitches, magnitudes = librosa.core.piptrack(
            y=y, sr=sr,
            n_fft=frame_length,
            hop_length=hop_length,
            fmin=50,
            fmax=400
        )

        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ—Ä–µ–π–º–∞ –±–µ—Ä–µ–º —á–∞—Å—Ç–æ—Ç—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –º–∞–≥–Ω–∏—Ç—É–¥–æ–π
        pitch_values = []
        magnitude_values = []

        for t in range(pitches.shape[1]):
            index = magnitudes[:, t].argmax()
            pitch = pitches[index, t]
            magnitude = magnitudes[index, t]

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–Ω—É–ª–µ–≤—ã–µ —á–∞—Å—Ç–æ—Ç—ã (–≤–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏)
            if pitch > 0 and magnitude > 0:
                pitch_values.append(pitch)
                magnitude_values.append(magnitude)

        # –ï—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—Ä–µ–π–º–æ–≤
        if len(pitch_values) < 5:
            return np.zeros(8)

        pitch_values = np.array(pitch_values)
        magnitude_values = np.array(magnitude_values)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–∂–∏—Ç—Ç–µ—Ä–∞ (–≤–∞—Ä–∏–∞—Ü–∏–∏ –ø–µ—Ä–∏–æ–¥–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–æ–Ω–∞)
        periods = 1.0 / pitch_values
        period_diffs = np.abs(np.diff(periods))

        # –õ–æ–∫–∞–ª—å–Ω—ã–π –¥–∂–∏—Ç—Ç–µ—Ä (–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π —Ä–∞–∑–Ω–∏—Ü—ã –∫ —Å—Ä–µ–¥–Ω–µ–º—É –ø–µ—Ä–∏–æ–¥—É)
        local_jitter = np.mean(period_diffs) / np.mean(periods) * 100

        # –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –¥–∂–∏—Ç—Ç–µ—Ä (—Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞)
        absolute_jitter = np.mean(period_diffs) * 1000  # –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

        # PPQ5 (5-point period perturbation quotient)
        ppq5_values = []
        for i in range(2, len(periods) - 2):
            avg_period = np.mean(periods[i - 2:i + 3])
            ppq5_values.append(abs(periods[i] - avg_period))
        ppq5 = np.mean(ppq5_values) / np.mean(periods) * 100 if ppq5_values else 0

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —à–∏–º–º–µ—Ä–∞ (–≤–∞—Ä–∏–∞—Ü–∏–∏ –∞–º–ø–ª–∏—Ç—É–¥—ã)
        amplitude_diffs = np.abs(np.diff(magnitude_values))

        # –õ–æ–∫–∞–ª—å–Ω—ã–π —à–∏–º–º–µ—Ä
        local_shimmer = np.mean(amplitude_diffs) / np.mean(magnitude_values) * 100

        # –ê–±—Å–æ–ª—é—Ç–Ω—ã–π —à–∏–º–º–µ—Ä (–≤ –¥–ë)
        db_values = 20 * np.log10(magnitude_values / np.max(magnitude_values))
        db_diffs = np.abs(np.diff(db_values))
        absolute_shimmer_db = np.mean(db_diffs)

        # APQ5 (5-point amplitude perturbation quotient)
        apq5_values = []
        for i in range(2, len(magnitude_values) - 2):
            avg_amp = np.mean(magnitude_values[i - 2:i + 3])
            apq5_values.append(abs(magnitude_values[i] - avg_amp))
        apq5 = np.mean(apq5_values) / np.mean(magnitude_values) * 100 if apq5_values else 0

        # –í–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = np.array([
            local_jitter,
            absolute_jitter,
            ppq5,
            np.std(period_diffs) / np.mean(periods) * 100,  # –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –¥–∂–∏—Ç—Ç–µ—Ä–∞
            local_shimmer,
            absolute_shimmer_db,
            apq5,
            np.std(amplitude_diffs) / np.mean(magnitude_values) * 100  # –≤–∞—Ä–∏–∞–±–µ–ª—å–Ω–æ—Å—Ç—å —à–∏–º–º–µ—Ä–∞
        ])

        return features
    except Exception as e:
        log.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –¥–∂–∏—Ç—Ç–µ—Ä–∞/—à–∏–º–º–µ—Ä–∞: {e}")
        return np.zeros(8)


def extract_yamnet(y: np.ndarray, sr: int) -> np.ndarray:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø–æ–º–æ—â—å—é YAMNet.

    Args:
        y: –ê—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª
        sr: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

    Returns:
        –í–µ–∫—Ç–æ—Ä embedding –∏–∑ YAMNet
    """
    try:
        # –ü—Ä–∏–≤–µ—Å—Ç–∏ —á–∞—Å—Ç–æ—Ç—É –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ –∫ —Ç—Ä–µ–±—É–µ–º–æ–π –¥–ª—è YAMNet
        if sr != 16000:
            y = librosa.resample(y, orig_sr=sr, target_sr=16000)

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä
        waveform = tf.convert_to_tensor(y, dtype=tf.float32)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ YAMNet
        _, embeddings, _ = lazy_yamnet()(waveform)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        return embeddings.numpy().mean(axis=0)
    except Exception as e:
        log.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ YAMNet –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        return np.zeros(1024)  # YAMNet embeddings –∏–º–µ—é—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å 1024


def calculate_confidence_interval(similarities: List[float]) -> Tuple[float, float]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞.

    Args:
        similarities: –°–ø–∏—Å–æ–∫ –æ—Ü–µ–Ω–æ–∫ —Å—Ö–æ–¥—Å—Ç–≤–∞

    Returns:
        (lower_bound, upper_bound): –ì—Ä–∞–Ω–∏—Ü—ã –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    """
    # –ï—Å–ª–∏ –æ—Ü–µ–Ω–æ–∫ –º–µ–Ω—å—à–µ 2, –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞
    if len(similarities) < 2:
        return (0.0, 1.0)

    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
    mean = np.mean(similarities)
    std_dev = np.std(similarities, ddof=1)  # –ù–µ—Å–º–µ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

    # –°—Ç–µ–ø–µ–Ω–∏ —Å–≤–æ–±–æ–¥—ã
    df = len(similarities) - 1

    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ t-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–æ–≤–µ—Ä–∏—è
    t_crit = scipy.stats.t.ppf((1 + CONFIDENCE_LEVEL) / 2, df)

    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ
    sem = std_dev / np.sqrt(len(similarities))

    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
    margin_of_error = t_crit * sem
    lower_bound = max(0.0, mean - margin_of_error)
    upper_bound = min(1.0, mean + margin_of_error)

    return (lower_bound, upper_bound)


def compare_voices_dual(file1: str, file2: str, weights: dict = weights) -> Tuple[str, str]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤.

    Args:
        file1: –ü—É—Ç—å –∫ –ø–µ—Ä–≤–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        file2: –ü—É—Ç—å –∫–æ –≤—Ç–æ—Ä–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
        weights: –í–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏

    Returns:
        (verdict, summary): –í–µ—Ä–¥–∏–∫—Ç –æ —Å—Ö–æ–¥—Å—Ç–≤–µ –∏ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
    """
    log.info(f"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤: {file1} –∏ {file2}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
    y1, _ = librosa.load(file1, sr=SAMPLE_RATE)
    y2, _ = librosa.load(file2, sr=SAMPLE_RATE)

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    y1 = preprocess(y1)
    y2 = preprocess(y2)

    # === –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –≥–æ–ª–æ—Å —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ AntiSpoofing ===
    antispoofing = lazy_antispoofing()
    spoof_result1 = antispoofing.detect(y1, SAMPLE_RATE)
    spoof_result2 = antispoofing.detect(y2, SAMPLE_RATE)

    synthetic_warning = ""
    is_synthetic = False

    if spoof_result1["is_synthetic"] > 0.7 or spoof_result2["is_synthetic"] > 0.7:
        synthetic_warning = (
            f"üö® –í–ê–ñ–ù–û–ï –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞ –∏–ª–∏ deepfake!\n"
            f"–§–∞–π–ª 1: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞ {spoof_result1['is_synthetic']:.1%}\n"
            f"–§–∞–π–ª 2: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞ {spoof_result2['is_synthetic']:.1%}\n"
            f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫—Ä–∞–π–Ω–µ –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞.\n\n"
        )
        is_synthetic = True

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—é –≥–æ–ª–æ—Å–∞
    mod1, mod_type1 = detect_voice_modification(y1, SAMPLE_RATE)
    mod2, mod_type2 = detect_voice_modification(y2, SAMPLE_RATE)

    modification_warning = ""
    if mod1 or mod2:
        modification_warning = (
            f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞!\n"
            f"–§–∞–π–ª 1: {'–î–∞, —Ç–∏–ø: ' + mod_type1 if mod1 else '–ù–µ—Ç'}\n"
            f"–§–∞–π–ª 2: {'–î–∞, —Ç–∏–ø: ' + mod_type2 if mod2 else '–ù–µ—Ç'}\n"
            f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–∫–∞–∂–µ–Ω—ã.\n\n"
        )

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ—á–µ–≤—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    segments1 = get_segments(y1, SAMPLE_RATE)
    segments2 = get_segments(y2, SAMPLE_RATE)

    # –ï—Å–ª–∏ —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤—ã–¥–∞–µ–º –æ—à–∏–±–∫—É
    if not segments1 or not segments2:
        return (
            "‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: –≤ –æ–¥–Ω–æ–º –∏–ª–∏ –æ–±–æ–∏—Ö —Ñ–∞–π–ª–∞—Ö –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—á–∏",
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –≥–æ–ª–æ—Å –∏ –Ω–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã."
        )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    sims = {
        "ecapa": [],  # –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (ECAPA-TDNN)
        "xvec": [],  # –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (X-vector)
        "res": [],  # –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (Resemblyzer)
        "formant": [],  # –ë–∞–∑–æ–≤—ã–µ —Ñ–æ—Ä–º–∞–Ω—Ç—ã
        "formant_dynamics": [],  # –î–∏–Ω–∞–º–∏–∫–∞ —Ñ–æ—Ä–º–∞–Ω—Ç
        "fricative": [],  # –§—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –∑–≤—É–∫–∏
        "nasal": [],  # –ù–æ—Å–æ–≤—ã–µ —Ä–µ–∑–æ–Ω–∞–Ω—Å—ã
        "vocal_tract": [],  # –î–ª–∏–Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞
        "jitter_shimmer": [],  # –ú–∏–∫—Ä–æ–≤–∞—Ä–∏–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞
        "yamnet": [],  # –ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        "voice_features": [],  # –ë–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ (–Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å)
        "formant_tracker": []  # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º–∞–Ω—Ç (–Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å)
    }

    # === –ù–û–í–û–ï: –ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ä–º–∞–Ω—Ç —á–µ—Ä–µ–∑ FormantTracker ===
    formant_tracker = lazy_formant_tracker()
    formant_tracks1 = formant_tracker.track_formants(y1)
    formant_tracks2 = formant_tracker.track_formants(y2)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ñ–æ—Ä–º–∞–Ω—Ç –¥–ª—è –æ–±–æ–∏—Ö –≥–æ–ª–æ—Å–æ–≤
    formant_stats1 = formant_tracker.compute_formant_statistics(formant_tracks1)
    formant_stats2 = formant_tracker.compute_formant_statistics(formant_tracks2)

    # –û—Ü–µ–Ω–∫–∞ –≤–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞ –¥–ª—è –æ–±–æ–∏—Ö –≥–æ–ª–æ—Å–æ–≤
    vocal_tract_estimate1 = formant_tracker.estimate_vocal_tract_length(formant_tracks1)
    vocal_tract_estimate2 = formant_tracker.estimate_vocal_tract_length(formant_tracks2)

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π
    formant_comparison = formant_tracker.compare_formant_profiles(formant_stats1, formant_stats2)

    # === –ù–û–í–û–ï: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–ª–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —á–µ—Ä–µ–∑ VoiceFeatureExtractor ===
    voice_features = lazy_voice_features()
    features1 = voice_features.extract_all_features(y1)
    features2 = voice_features.extract_all_features(y2)

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
    voice_features_comparison = voice_features.compare_voice_features(features1, features2)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    ecapa = lazy_ecapa()
    xvector = lazy_xvector()
    res = lazy_res()

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    for s1, s2 in zip(segments1, segments2):
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä—ã –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        t1 = torch.tensor(s1).unsqueeze(0)
        t2 = torch.tensor(s2).unsqueeze(0)

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ ECAPA-TDNN
        sims["ecapa"].append(cosine_similarity(
            ecapa.encode_batch(t1).squeeze().detach().numpy(),
            ecapa.encode_batch(t2).squeeze().detach().numpy()
        ))

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Resemblyzer
        sims["res"].append(cosine_similarity(
            res.embed_utterance(s1), res.embed_utterance(s2)))

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ X-vector
        sims["xvec"].append(cosine_similarity(
            xvector(t1).squeeze().numpy(), xvector(t2).squeeze().numpy()))

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ñ–æ—Ä–º–∞–Ω—Ç
        formants1 = extract_formants_advanced(s1, SAMPLE_RATE)
        formants2 = extract_formants_advanced(s2, SAMPLE_RATE)

        if formants1 is not None and formants2 is not None:
            # –§–æ—Ä–º–∞–Ω—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Å—Ö–æ–¥—Å—Ç–≤–æ F1-F4)
            formant_vector1 = np.concatenate([
                np.mean(formants1["F1"]) if formants1["F1"].size > 0 else np.array([0]),
                np.mean(formants1["F2"]) if formants1["F2"].size > 0 else np.array([0]),
                np.mean(formants1["F3"]) if formants1["F3"].size > 0 else np.array([0]),
                np.mean(formants1["F4"]) if formants1["F4"].size > 0 else np.array([0])
            ])

            formant_vector2 = np.concatenate([
                np.mean(formants2["F1"]) if formants2["F1"].size > 0 else np.array([0]),
                np.mean(formants2["F2"]) if formants2["F2"].size > 0 else np.array([0]),
                np.mean(formants2["F3"]) if formants2["F3"].size > 0 else np.array([0]),
                np.mean(formants2["F4"]) if formants2["F4"].size > 0 else np.array([0])
            ])

            sims["formant"].append(cosine_similarity(formant_vector1, formant_vector2))

            # –î–∏–Ω–∞–º–∏–∫–∞ —Ñ–æ—Ä–º–∞–Ω—Ç
            dynamics1 = extract_formant_dynamics(formants1)
            dynamics2 = extract_formant_dynamics(formants2)
            sims["formant_dynamics"].append(cosine_similarity(dynamics1, dynamics2))

            # –î–ª–∏–Ω–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞
            vtl1 = extract_vocal_tract_length(formants1)
            vtl2 = extract_vocal_tract_length(formants2)
            # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –¥–ª–∏–Ω—ã —Ç—Ä–∞–∫—Ç–∞ (–∞–±—Å–æ–ª—é—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞)
            vtl_sim = 1.0 - min(abs(vtl1 - vtl2) / 5.0, 1.0)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ 5 —Å–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–∑–Ω–∏—Ü—ã
            sims["vocal_tract"].append(vtl_sim)

        # –§—Ä–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –∑–≤—É–∫–∏
        fricative1 = extract_fricative_features(s1, SAMPLE_RATE)
        fricative2 = extract_fricative_features(s2, SAMPLE_RATE)
        sims["fricative"].append(cosine_similarity(fricative1, fricative2))

        # –ù–æ—Å–æ–≤—ã–µ —Ä–µ–∑–æ–Ω–∞–Ω—Å—ã
        nasal1 = extract_nasal_features(s1, SAMPLE_RATE)
        nasal2 = extract_nasal_features(s2, SAMPLE_RATE)
        sims["nasal"].append(cosine_similarity(nasal1, nasal2))

        # –î–∂–∏—Ç—Ç–µ—Ä –∏ —à–∏–º–º–µ—Ä
        jitter_shimmer1 = extract_jitter_shimmer(s1, SAMPLE_RATE)
        jitter_shimmer2 = extract_jitter_shimmer(s2, SAMPLE_RATE)
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è –¥–∂–∏—Ç—Ç–µ—Ä–∞/—à–∏–º–º–µ—Ä–∞ - —á–µ–º –±–ª–∏–∂–µ, —Ç–µ–º –≤—ã—à–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        js_diff = np.abs(jitter_shimmer1 - jitter_shimmer2)
        js_sim = 1.0 - np.mean(np.minimum(js_diff / np.array([2.0, 5.0, 2.0, 3.0, 5.0, 3.0, 5.0, 5.0]), 1.0))
        sims["jitter_shimmer"].append(js_sim)

        # YAMNet –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        yamnet1 = extract_yamnet(s1, SAMPLE_RATE)
        yamnet2 = extract_yamnet(s2, SAMPLE_RATE)
        sims["yamnet"].append(cosine_similarity(yamnet1, yamnet2))

        # === –ù–û–í–û–ï: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ===
        segment_features1 = voice_features.extract_all_features(s1)
        segment_features2 = voice_features.extract_all_features(s2)

        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
        segment_comparison = voice_features.compare_voice_features(segment_features1, segment_features2)
        sims["voice_features"].append(segment_comparison["overall"])

        # === –ù–û–í–û–ï: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞–Ω—Ç–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ===
        segment_formant_tracks1 = formant_tracker.track_formants(s1)
        segment_formant_tracks2 = formant_tracker.track_formants(s2)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞–Ω—Ç –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        segment_formant_stats1 = formant_tracker.compute_formant_statistics(segment_formant_tracks1)
        segment_formant_stats2 = formant_tracker.compute_formant_statistics(segment_formant_tracks2)

        segment_formant_comparison = formant_tracker.compare_formant_profiles(
            segment_formant_stats1, segment_formant_stats2)

        if "overall" in segment_formant_comparison:
            sims["formant_tracker"].append(segment_formant_comparison["overall"])

    # === –ù–û–í–û–ï: –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –æ–±—â–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–æ–ª–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ ===
    # –≠—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–∂–Ω—ã –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ—á–µ–≤–æ–π –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏
    if "overall" in formant_comparison:
        sims["formant_tracker"].append(formant_comparison["overall"])

    if "overall" in voice_features_comparison:
        sims["voice_features"].append(voice_features_comparison["overall"])

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
    summary = synthetic_warning + modification_warning
    weighted_total = 0
    weighted_score = 0

    # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    summary += "| –ú–µ—Ç—Ä–∏–∫–∞ | –ú–µ–¥–∏–∞–Ω–∞ | 95% CI | >0.90 | –í–µ—Å |\n"
    summary += "| ------- | ------- | ------ | ----- | --- |\n"

    all_medians = []  # –î–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    for key, values in sims.items():
        if not values:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–π
            continue

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–µ
        med = np.median(values)
        all_medians.append(med)
        count_high = sum(1 for x in values if x > 0.9)
        ci_low, ci_high = calculate_confidence_interval(values)

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ —à–∏—Ä–∏–Ω–µ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
        ci_width = ci_high - ci_low
        confidence = "üü¢" if ci_width < 0.1 else "üü°" if ci_width < 0.2 else "üî¥"

        # –ú–µ—Ç–∫–∞ –¥–ª—è –º–µ–¥–∏–∞–Ω—ã
        label = "üü¢" if med > 0.85 else "üü°" if med > 0.7 else "üî¥"

        # –í–µ—Å–æ–≤–æ–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
        weight = weights.get(key, 1.0)
        weighted_total += weight
        weighted_score += weight * med

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü—É
        summary += f"| {label} {key.upper()} | {med:.3f} | {ci_low:.2f}-{ci_high:.2f} {confidence} | {count_high}/{len(values)} | {weight} |\n"

    # –†–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏
    final_score = weighted_score / weighted_total if weighted_total > 0 else 0

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
    consistency = np.std(all_medians)
    consistency_label = "üü¢" if consistency < 0.05 else "üü°" if consistency < 0.15 else "üî¥"

    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏
    confidence_range = f"{final_score:.2f} ¬± {consistency:.2f}"

    # === –ù–û–í–û–ï: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–æ–∫–∞–ª—å–Ω–æ–º —Ç—Ä–∞–∫—Ç–µ ===
    if vocal_tract_estimate1 and vocal_tract_estimate2 and "mean" in vocal_tract_estimate1 and "mean" in vocal_tract_estimate2:
        vtl1_mean = vocal_tract_estimate1["mean"]
        vtl2_mean = vocal_tract_estimate2["mean"]
        vtl_diff = abs(vtl1_mean - vtl2_mean)

        vtl_assessment = (
            f"\n**–ê–Ω–∞–ª–∏–∑ –¥–ª–∏–Ω—ã –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ç—Ä–∞–∫—Ç–∞:**\n"
            f"–§–∞–π–ª 1: {vtl1_mean:.1f} —Å–º\n"
            f"–§–∞–π–ª 2: {vtl2_mean:.1f} —Å–º\n"
            f"–†–∞–∑–Ω–∏—Ü–∞: {vtl_diff:.2f} —Å–º\n"
        )

        vtl_conclusion = ""
        if vtl_diff < 0.5:
            vtl_conclusion = "‚úÖ –î–ª–∏–Ω—ã –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ç—Ä–∞–∫—Ç–æ–≤ –æ—á–µ–Ω—å –±–ª–∏–∑–∫–∏, —á—Ç–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞"
        elif vtl_diff < 1.0:
            vtl_conclusion = "üü° –ù–µ–±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –¥–ª–∏–Ω–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ç—Ä–∞–∫—Ç–æ–≤, –≤–æ–∑–º–æ–∂–Ω–æ –æ–¥–∏–Ω —á–µ–ª–æ–≤–µ–∫ —Å —Ä–∞–∑–Ω–æ–π –∞—Ä—Ç–∏–∫—É–ª—è—Ü–∏–µ–π"
        else:
            vtl_conclusion = "‚ùå –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –¥–ª–∏–Ω–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Ç—Ä–∞–∫—Ç–æ–≤, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–∞—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ª—é–¥–µ–π"

        summary += vtl_assessment + vtl_conclusion + "\n\n"

    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –≤ –æ—Ç—á–µ—Ç
    summary += f"\n**–ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞: {final_score:.3f}** (–∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤: {consistency_label} ¬±{consistency:.2f})\n"
    summary += f"**–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª: {confidence_range}**\n\n"

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–¥–∏–∫—Ç–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–≤ –∏ –Ω–∞–ª–∏—á–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ—á–∏
    verdict = ""

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –≥–æ–ª–æ—Å –ø–µ—Ä–µ–¥ –≤—ã–Ω–µ—Å–µ–Ω–∏–µ–º –≤–µ—Ä–¥–∏–∫—Ç–∞
    if is_synthetic:
        verdict = "‚ö†Ô∏è –†–ï–ó–£–õ–¨–¢–ê–¢ –ù–ï–ù–ê–î–ï–ñ–ï–ù: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≥–æ–ª–æ—Å–∞ (deepfake)"
        if final_score >= 0.85:
            verdict += "\n–ü—Ä–∏ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ deepfake —Å—Ö–æ–¥—Å—Ç–≤–æ –≤—ã—Å–æ–∫–æ–µ, –Ω–æ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∫–∞–∫ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ"
    else:
        if final_score >= 0.95 and consistency < 0.1:
            verdict = "‚úÖ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: –ì–æ–ª–æ—Å–∞ —Å –≤—ã—Å–æ—á–∞–π—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –æ–¥–Ω–æ–º—É –∏ —Ç–æ–º—É –∂–µ —á–µ–ª–æ–≤–µ–∫—É"
        elif final_score >= 0.88 and consistency < 0.12:
            verdict = "‚úÖ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: –ì–æ–ª–æ—Å–∞ —Å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –æ–¥–Ω–æ–º—É –∏ —Ç–æ–º—É –∂–µ —á–µ–ª–æ–≤–µ–∫—É"
        elif final_score >= 0.80 and consistency < 0.15:
            verdict = "üü° –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: –ì–æ–ª–æ—Å–∞, –≤–µ—Ä–æ—è—Ç–Ω–æ, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –æ–¥–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É, –Ω–æ —Ç—Ä–µ–±—É—é—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è"
        elif final_score >= 0.70:
            verdict = "‚ö†Ô∏è –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: –ò–º–µ–µ—Ç—Å—è –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –≥–æ–ª–æ—Å–æ–≤, –Ω–æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞"
        else:
            verdict = "‚ùå –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –≠–ö–°–ü–ï–†–¢–ê: –ì–æ–ª–æ—Å–∞ —Å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç —Ä–∞–∑–Ω—ã–º –ª—é–¥—è–º"

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏—è –∫ –≤–µ—Ä–¥–∏–∫—Ç—É
    if mod1 or mod2:
        verdict += "\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞"

    if consistency > 0.15:
        verdict += "\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í—ã—Å–æ–∫–∞—è –Ω–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–µ–∂–¥—É –º–µ—Ç–æ–¥–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã–º–∏"

    return verdict, summary
